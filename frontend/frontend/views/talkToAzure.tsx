import React, { useState, useEffect, useRef } from 'react';
import './WebRtcChat.css';
import { Notification } from '@vaadin/react-components/Notification.js';
import withAuth from 'Frontend/components/withAuth';

export const config: ViewConfig = { menu: { order: 6, icon: 'vaadin:bold' }, title: 'è€æ¿é¢è¯•' };

function talkToAzure() {
  const [personality, setPersonality] = useState(null); // 1-è‘£æ˜ç  2-é›·å†›
  const [messages, setMessages] = useState([]);
  const [connectionState, setConnectionState] = useState('disconnected');
  const [audioLevel, setAudioLevel] = useState(0);
  const [bars, setBars] = useState([]);

  const peerConnectionRef = useRef(null);
  const audioOutputRef = useRef(null);
  const eventSourceRef = useRef(null);
  const boxContainerRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const animationIdRef = useRef(null);
  const dataArrayRef = useRef(new Uint8Array(32));

  // äººæ ¼å›¾ç‰‡é…ç½®
  const PERSONALITIES = [
    {
      id: 1,
      name: 'è‘£æ˜ç ',
      image: '/images/dongmingzhu.jpg',
      style: { borderColor: '#e74c3c' },
      description: 'æ ¼åŠ›å¼é«˜å‹é¢è¯•ï¼Œæ³¨é‡ç»†èŠ‚ä¸æ‰§è¡ŒåŠ›'
    },
    {
      id: 2,
      name: 'é›·å†›',
      image: '/images/leijun.jpg',
      style: { borderColor: '#3498db' },
      description: 'å°ç±³æ–¹æ³•è®ºï¼Œæè‡´æ€§ä»·æ¯”æ€ç»´'
    },
    {
      id: 3,
      name: 'åŸƒéš†Â·é©¬æ–¯å…‹',
      image: '/images/elonmusk.jpg',
      style: { borderColor: '#00ff00' },
      description: 'ç¬¬ä¸€æ€§åŸç†æ‹·é—®ï¼Œç«æ˜Ÿæ®–æ°‘æ€ç»´'
    },
    {
      id: 4,
      name: 'å”çº³å¾·Â·ç‰¹æœ—æ™®',
      image: '/images/trump.jpg',
      style: {
        borderColor: '#ff0000',
        boxShadow: '0 0 10px gold'
      },
      description: 'ã€Šå­¦å¾’ã€‹å¼çœŸäººç§€ï¼Œå•†ä¸šè°ˆåˆ¤é«˜æ‰‹'
    }
  ];

  // Initialize audio bars
  useEffect(() => {
    const numBars = 32;
    const newBars = Array(numBars).fill(0).map((_, i) => (
      <div
        key={i}
        className="box"
        style={{
          '--boxSize': `${100 / numBars}%`,
          transform: 'scaleY(0.1)'
        }}
      />
    ));
    setBars(newBars);

    return () => {
      if (animationIdRef.current) {
        cancelAnimationFrame(animationIdRef.current);
      }
    };
  }, []);

  // Audio visualization update
  const updateVisualization = () => {
    if (!analyserRef.current || !boxContainerRef.current) return;

    analyserRef.current.getByteFrequencyData(dataArrayRef.current);
    const boxes = boxContainerRef.current.querySelectorAll('.box');

    boxes.forEach((box, i) => {
      const barHeight = (dataArrayRef.current[i] / 255) * 2;
      box.style.transform = `scaleY(${Math.max(0.1, barHeight)})`;
    });

    // Calculate overall audio level for the pulse indicator
    const average = dataArrayRef.current.reduce((a, b) => a + b, 0) / dataArrayRef.current.length;
    setAudioLevel(average / 255);

    animationIdRef.current = requestAnimationFrame(updateVisualization);
  };

  // Initialize audio context and analyzer
  const initAudioContext = (stream) => {
    const audioContext = new (window.AudioContext || window.webkitAudioContext)();
    const analyser = audioContext.createAnalyser();
    const audioSource = audioContext.createMediaStreamSource(stream);

    analyser.fftSize = 64;
    audioSource.connect(analyser);
    dataArrayRef.current = new Uint8Array(analyser.frequencyBinCount);

    audioContextRef.current = audioContext;
    analyserRef.current = analyser;

    // Start visualization
    animationIdRef.current = requestAnimationFrame(updateVisualization);
  };

  // Show error message
  const showError = (message) => {
    console.error('Error:', message);
    // You could implement a toast notification here
  };

  // Establish WebRTC connection
  const startConnection = async () => {
    if (!personality) {
        Notification.show('è¯·å…ˆé€‰æ‹©é¢è¯•å®˜äººæ ¼', { theme: "error" });
        return;
    }
    const webrtc_id = Math.random().toString(36).substring(7);
    try {
      setConnectionState('connecting');

      // 1. Get user media stream
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      initAudioContext(stream);

      // 2. Create PeerConnection
      const peerConnection = new RTCPeerConnection({
        iceServers: [
          { urls: 'stun:stun.l.google.com:19302' }
          // Add TURN servers if needed
        ]
      });
      peerConnectionRef.current = peerConnection;

      // 3. Add audio tracks
      stream.getTracks().forEach(track => peerConnection.addTrack(track, stream));

      // 4. Handle remote stream
      peerConnection.ontrack = (event) => {
        if (audioOutputRef.current.srcObject !== event.streams[0]) {
          audioOutputRef.current.srcObject = event.streams[0];
          audioOutputRef.current.play().catch(e => console.error('Audio play failed:', e));
        }
      };

      // 5. Create data channel for error messages
      const dataChannel = peerConnection.createDataChannel('text');
      dataChannel.onmessage = (event) => {
        const eventJson = JSON.parse(event.data);
        if (eventJson.type === "error") {
          showError(eventJson.message);
        }else if (eventJson.type === "send_input") {
           fetch('/api/webrtc/personality', {
                 method: 'POST',
                 headers: { 'Content-Type': 'application/json' },
                 body: JSON.stringify({
                     webrtc_id: webrtc_id,
                     personality: personality.toString()
                 })
            });
         }
      };

      // 6. Create and send offer
      const offer = await peerConnection.createOffer();
      await peerConnection.setLocalDescription(offer);

      const response = await fetch('/api/webrtc/offer', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          sdp: offer.sdp,
          type: offer.type,
          webrtc_id
        })
      });

      // 7. Set remote description
      const answer = await response.json();
      await peerConnection.setRemoteDescription(answer);

      // 8. Establish SSE connection
      eventSourceRef.current = new EventSource(`/api/webrtc/outputs?webrtc_id=${webrtc_id}`);
      eventSourceRef.current.addEventListener('output', (event) => {
        const data = JSON.parse(event.data);
        setMessages(prev => [...prev, { role: 'assistant', content: data.content }]);
      });

      setConnectionState('connected');
    } catch (error) {
      console.error('Connection failed:', error);
      setConnectionState('error');
      stopConnection();
    }
  };

  // Close connection
  const stopConnection = () => {
    if (peerConnectionRef.current) {
      peerConnectionRef.current.close();
      peerConnectionRef.current = null;
    }
    if (eventSourceRef.current) {
      eventSourceRef.current.close();
      eventSourceRef.current = null;
    }
    if (animationIdRef.current) {
      cancelAnimationFrame(animationIdRef.current);
      animationIdRef.current = null;
    }
    if (audioContextRef.current) {
      audioContextRef.current.close();
      audioContextRef.current = null;
    }
    setConnectionState('disconnected');
  };

  const handlePersonalitySelect = async (selectedId) => {
    setPersonality(selectedId);

    const selectedPerson = PERSONALITIES.find(p => p.id === selectedId);
    if (selectedId === 1) {
      Notification.show(`â„ è¿›å…¥${selectedPerson.name}æ¨¡å¼: æ ¼åŠ›å¼å‹åŠ›é¢è¯•å‡†å¤‡å°±ç»ªï¼Œè¯·è¯æ˜ä½ çš„ä»·å€¼ï¼`);
    } else if (selectedId === 2) {
       Notification.show(`ğŸš— è¿›å…¥${selectedPerson.name}æ¨¡å¼: æ€§ä»·æ¯”è¯„ä¼°æ¨¡å¼å¯åŠ¨ï¼Œè¯·å‡†å¤‡æ•°æ®åŒ–å›ç­”ï¼`);
    } else if (selectedId === 3) {
      Notification.show(`ğŸš€ è¿›å…¥${selectedPerson.name}æ¨¡å¼: å‡†å¤‡æ¥å—ç‰©ç†å­¦æ‹·é—®!`);
    } else if (selectedId === 4) {
      Notification.show(`ğŸ‘‘ è¿›å…¥${selectedPerson.name}æ¨¡å¼æ¿€æ´»: è¿™å°†æ˜¯å²ä¸Šæœ€æ£’çš„é¢è¯•!`);
    }
  }

  return (
    <div className="container">
      <div className="personality-selector">
        <h3>é€‰æ‹©é¢è¯•å®˜é£æ ¼ï¼š</h3>
        <div className="personality-options">
          {PERSONALITIES.map((p) => (
            <div
              key={p.id}
              className={`personality-card ${personality === p.id ? 'active' : ''}`}
              style={p.style}
              onClick={() => handlePersonalitySelect(p.id)}
              title={p.description}
            >
              <img src={p.image} alt={p.name} />
              <span>{p.name}</span>
              {personality === p.id && (
                <div className="selection-badge">âœ“</div>
              )}
            </div>
          ))}
        </div>
      </div>

      <div className="wave-container">
        <div className="box-container" ref={boxContainerRef}>
          {bars}
        </div>
      </div>

      <button onClick={connectionState === 'connected' ? stopConnection : startConnection}>
        {connectionState === 'connecting' ? (
          <div className="spinner">è¿æ¥...</div>
        ) : connectionState === 'connected' ? (
          <div className="pulse-indicator" style={{ '--audio-level': 1 + audioLevel }}>
            åœæ­¢
          </div>
        ) : (
          personality === 4 ? 'å¼€å§‹ (ç›¸ä¿¡æˆ‘!)' : 'å¼€å§‹'
        )}
      </button>

      <audio ref={audioOutputRef} hidden />
    </div>
  );
}

export default withAuth(talkToAzure);